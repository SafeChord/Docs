---
title: "Service: Data Ingestor"
doc_id: safechord.safezone.service.dataingestor
version: "0.2.1"
status: active
authors:
  - bradyhau
  - Gemini 2.5 Pro
last_updated: "2025-09-12"
summary: "Data Ingestor æ˜¯ SafeZone ç³»çµ±çš„è³‡æ–™å…¥å£é–˜é“ (Gateway)ã€‚å®ƒæä¾› RESTful API æ¥æ”¶å¤–éƒ¨äº‹ä»¶ï¼Œä¸¦å°‡å…¶è½‰æ›ç‚ºæ¨™æº–åŒ–çš„ Kafka è¨Šæ¯ï¼Œå¯¦ç¾è³‡æ–™å¯«å…¥èˆ‡è™•ç†çš„éåŒæ­¥è§£è€¦ã€‚"
keywords:
  - Data Ingestor
  - Kafka Producer
  - Gateway
  - Event Driven
  - FastAPI
logical_path: "SafeChord.SafeZone.Service.DataIngestor"
related_docs:
  - "safechord.safezone.changelog.md"
  - "safechord.safezone.service.datasimulator.md"
  - "safechord.safezone.service.worker.md"
parent_doc: "safechord.safezone.service"
tech_stack:
  - Python 3.13
  - FastAPI
  - Kafka (aiokafka)
  - Pydantic
---

# Data Ingestor (v0.2.1)

## ğŸ“Œ æœå‹™å®šä½
Data Ingestor æ˜¯ç³»çµ±çš„ **å¯«å…¥é–˜é“ (Ingestion Gateway)**ã€‚
*   **è§’è‰²**: Producer (Kafka)ã€‚å®ƒä¸è² è²¬è³‡æ–™æŒä¹…åŒ– (Persistence)ï¼Œåƒ…è² è²¬è³‡æ–™é©—è­‰èˆ‡äº‹ä»¶ç™¼å¸ƒã€‚
*   **ç‰¹æ€§**: Stateless, High-Throughputã€‚è¨­è¨ˆç›®æ¨™æ˜¯å¿«é€Ÿæ¥æ”¶å¤§é‡ HTTP è«‹æ±‚ä¸¦å¸è¼‰è‡³ Kafkaï¼Œä»¥æ‡‰å°çªç™¼æµé‡ (Spike Traffic)ã€‚

---

## ğŸ› ï¸ æ ¸å¿ƒè¦æ ¼ (Specifications)

### 1. API æ¥å£èˆ‡è³‡æ–™å¥‘ç´„
æœ¬æœå‹™ä½œç‚ºè³‡æ–™å…¥å£ï¼Œå°è³‡æ–™æ ¼å¼æœ‰åš´æ ¼é©—è­‰è¦æ±‚ã€‚
*   **Input (HTTP)**: `CovidDataModel` (åƒè¦‹ `utils/pydantic_model/request.py`)ã€‚
*   **Output (Kafka)**: 
    *   Topic: ç”±ç’°å¢ƒè®Šæ•¸ `KAFKA_TOPIC` æ±ºå®š (Default: `covid.case.data`)ã€‚
    *   Schema: JSON åºåˆ—åŒ–ç‰©ä»¶ï¼ŒåŒ…å« `payload` (åŸå§‹æ•¸æ“š), `trace_id`, `event_time`ã€‚

### 2. å¤–éƒ¨ä¾è³´èˆ‡æ§åˆ¶ (Dependencies & Control)
*   **Control Plane (Trigger)**: è¢«å‹•æ¥æ”¶ä¾†è‡ª [Pandemic Simulator](safechord.safezone.service.datasimulator.md) çš„ HTTP POST è«‹æ±‚ã€‚
*   **Downstream**: [Kafka Cluster]ã€‚
    *   *Note*: æœå‹™å•Ÿå‹•æ™‚æœƒå»ºç«‹ `AIOKafkaProducer` é€£ç·šæ± ã€‚

---

## ğŸ§ª è¡Œç‚ºé©—è­‰ (Behavior Verification)

æœ¬æœå‹™çš„é©—è­‰é‚è¼¯é›†ä¸­ç®¡ç†æ–¼å–®ä¸€è¦æ ¼æª”ä¸­ã€‚

| ç¯„ç–‡ | è¦æ ¼æª”è·¯å¾‘ (Source of Truth) | æ¥­å‹™æ„åœ– (Business Intent) |
| :--- | :--- | :--- |
| **æ•´åˆè¡Œç‚º** | `test/cases.json` | å®šç¾©äº†æ‰€æœ‰ API å ´æ™¯ï¼ŒåŒ…å«ï¼š<br>1. **æ­£å¸¸å¯«å…¥**: æ¥æ”¶æœ‰æ•ˆ JSON -> å›å‚³ 200 OKã€‚<br>2. **æ ¼å¼é©—è­‰**: æ—¥æœŸæ ¼å¼éŒ¯èª¤ã€æ¬„ä½ç¼ºå¤± -> å›å‚³ 422 Unprocessable Entityã€‚<br>3. **æ¥­å‹™è¦å‰‡**: `cases` æ•¸é‡ <= 0 -> å›å‚³ 422ã€‚<br>4. **å¥åº·æª¢æŸ¥**: `/health` ç«¯é»å›å‚³æœå‹™ç‹€æ…‹ã€‚ |

> **æ³¨æ„**: ç›®å‰æ¸¬è©¦å¥—ä»¶ä½¿ç”¨ `AsyncMock` æ¨¡æ“¬ Kafka Producer è¡Œç‚ºï¼Œå´é‡æ–¼ API å±¤èˆ‡è³‡æ–™é©—è­‰é‚è¼¯çš„æ¸¬è©¦ã€‚

---

## ğŸ§© è¨­è¨ˆæ¬Šè¡¡ (Design Trade-offs)

### 1. ç‚ºä»€éº¼å¾ç›´æ¥å¯«å…¥ DB (v0.1) æ”¹ç‚ºå¯«å…¥ Kafka (v0.2)ï¼Ÿ
*   **å‰Šå³°å¡«è°· (Peak Shaving)**: ç•¶ Simulator é€²è¡Œå£“åŠ›æ¸¬è©¦æ™‚ï¼Œç¬é–“æµé‡å¯èƒ½è¶…é PostgreSQL çš„é€£ç·šæ•¸ä¸Šé™ã€‚å¼•å…¥ Kafka ä½œç‚ºç·©è¡ï¼Œå…è¨± Ingestor ä»¥æ¥µé«˜çš„ååé‡æ¥æ”¶è«‹æ±‚ï¼Œè€Œ Worker å¯ä»¥ä¾ç…§ DB çš„è™•ç†èƒ½åŠ›æ…¢æ…¢æ¶ˆåŒ–ã€‚
*   **è§£è€¦ (Decoupling)**: Ingestor ä¸å†éœ€è¦çŸ¥é“ DB Schemaï¼Œåªéœ€é—œæ³¨è³‡æ–™æ ¼å¼ã€‚é€™è®“å¾Œç«¯å„²å­˜æ¶æ§‹çš„è®Šæ›´ï¼ˆå¦‚æ› DBï¼‰ä¸æœƒå½±éŸ¿åˆ°è³‡æ–™å…¥å£ã€‚

### 2. è³‡æ–™ä¸€è‡´æ€§è€ƒé‡
*   **Producer Acks**: é…ç½® `acks="all"` èˆ‡ `enable_idempotence=True`ï¼Œç¢ºä¿è¨Šæ¯åœ¨ Kafka ç«¯è¢«æŒä¹…åŒ–å¾Œæ‰å›å‚³ HTTP 200 çµ¦å®¢æˆ¶ç«¯ï¼Œé˜²æ­¢è³‡æ–™ä¸Ÿå¤±ã€‚

---

## ğŸš€ éƒ¨ç½²èˆ‡ç¶­é‹
*   **Docker Image**: `safezone-data-ingestor`
*   **ç’°å¢ƒè®Šæ•¸**:
    *   `KAFKA_BOOTSTRAP`: Kafka é€£ç·šåœ°å€
    *   `KAFKA_TOPIC`: ç›®æ¨™ Topic
*   **Health Check**: `GET /health`